{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIxP4dHLi2aac+JqVhRMLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianAnaya25/Sebastian-Anaya/blob/main/TensorflowKerasPyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksOSFef5vL80",
        "outputId": "a45d944e-f231-4dae-fde7-fcd36b554ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos iniciales: [-1.1037222 -1.177611 ]\n",
            "Umbral inicial (theta): -1.0831899642944336\n",
            "\n",
            "--- Época 1 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.49486714601516724\n",
            "Pérdida actual: 0.2551591992378235\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.4827151298522949\n",
            "Pérdida actual: 0.2675836384296417\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.2504960298538208\n",
            "Pérdida actual: 0.0627482607960701\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.7548912167549133\n",
            "Pérdida actual: 0.5698607563972473\n",
            "Pérdida promedio en la época 1: 0.28883796371519566\n",
            "Pesos actualizados: [-1.0878742 -1.1611836]\n",
            "Umbral actualizado (theta): -1.096935749053955\n",
            "\n",
            "--- Época 2 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5022653341293335\n",
            "Pérdida actual: 0.2477397918701172\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.49016091227531433\n",
            "Pérdida actual: 0.2599358558654785\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.2589591443538666\n",
            "Pérdida actual: 0.06705983728170395\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.7571955919265747\n",
            "Pérdida actual: 0.5733451843261719\n",
            "Pérdida promedio en la época 2: 0.2870201673358679\n",
            "Pesos actualizados: [-1.0729268 -1.1456404]\n",
            "Umbral actualizado (theta): -1.109523057937622\n",
            "\n",
            "--- Época 3 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5091480612754822\n",
            "Pérdida actual: 0.24093562364578247\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.497104287147522\n",
            "Pérdida actual: 0.25290408730506897\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.26704102754592896\n",
            "Pérdida actual: 0.07131090760231018\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.759282112121582\n",
            "Pérdida actual: 0.5765092968940735\n",
            "Pérdida promedio en la época 3: 0.2854149788618088\n",
            "Pesos actualizados: [-1.058846 -1.13095 ]\n",
            "Umbral actualizado (theta): -1.1209925413131714\n",
            "\n",
            "--- Época 4 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5155316591262817\n",
            "Pérdida actual: 0.23470957577228546\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5035606026649475\n",
            "Pérdida actual: 0.24645207822322845\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.2747286558151245\n",
            "Pérdida actual: 0.07547583431005478\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.7611628174781799\n",
            "Pérdida actual: 0.5793688297271729\n",
            "Pérdida promedio en la época 4: 0.2840015795081854\n",
            "Pesos actualizados: [-1.045594  -1.1170774]\n",
            "Umbral actualizado (theta): -1.1313903331756592\n",
            "\n",
            "--- Época 5 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5214359164237976\n",
            "Pérdida actual: 0.22902357578277588\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5095481276512146\n",
            "Pérdida actual: 0.24054303765296936\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.2820155918598175\n",
            "Pérdida actual: 0.07953279465436935\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.7628498077392578\n",
            "Pérdida actual: 0.5819398164749146\n",
            "Pérdida promedio en la época 5: 0.2827598061412573\n",
            "Pesos actualizados: [-1.0331304 -1.1039844]\n",
            "Umbral actualizado (theta): -1.1407660245895386\n",
            "\n",
            "--- Época 6 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5268829464912415\n",
            "Pérdida actual: 0.22383974492549896\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5150877237319946\n",
            "Pérdida actual: 0.23513992130756378\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.2889011800289154\n",
            "Pérdida actual: 0.0834638923406601\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.7643551230430603\n",
            "Pérdida actual: 0.5842387676239014\n",
            "Pérdida promedio en la época 6: 0.28167058154940605\n",
            "Pesos actualizados: [-1.0214132 -1.091631 ]\n",
            "Umbral actualizado (theta): -1.1491721868515015\n",
            "\n",
            "--- Época 7 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5318963527679443\n",
            "Pérdida actual: 0.2191210240125656\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5202017426490784\n",
            "Pérdida actual: 0.23020637035369873\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.29538944363594055\n",
            "Pérdida actual: 0.08725492656230927\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.765690803527832\n",
            "Pérdida actual: 0.5862824320793152\n",
            "Pérdida promedio en la época 7: 0.2807161882519722\n",
            "Pesos actualizados: [-1.0103995 -1.0799766]\n",
            "Umbral actualizado (theta): -1.1566623449325562\n",
            "\n",
            "--- Época 8 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5365006923675537\n",
            "Pérdida actual: 0.21483160555362701\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5249136686325073\n",
            "Pérdida actual: 0.2257070243358612\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.30148845911026\n",
            "Pérdida actual: 0.09089528769254684\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.7668682336807251\n",
            "Pérdida actual: 0.5880869030952454\n",
            "Pérdida promedio en la época 8: 0.2798802051693201\n",
            "Pesos actualizados: [-1.0000463 -1.0689795]\n",
            "Umbral actualizado (theta): -1.1632905006408691\n",
            "\n",
            "--- Época 9 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5407206416130066\n",
            "Pérdida actual: 0.2109375298023224\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5292472243309021\n",
            "Pérdida actual: 0.22160817682743073\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.30720949172973633\n",
            "Pérdida actual: 0.09437767416238785\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.767898440361023\n",
            "Pérdida actual: 0.5896680355072021\n",
            "Pérdida promedio en la época 9: 0.2791478540748358\n",
            "Pesos actualizados: [-0.9903114 -1.0585992]\n",
            "Umbral actualizado (theta): -1.16910982131958\n",
            "\n",
            "--- Época 10 ---\n",
            "\n",
            "Entrada: [1. 0.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5445809364318848\n",
            "Pérdida actual: 0.20740652084350586\n",
            "\n",
            "Entrada: [0. 1.], Salida deseada: 1.0\n",
            "Salida calculada: 0.5332260727882385\n",
            "Pérdida actual: 0.21787789463996887\n",
            "\n",
            "Entrada: [1. 1.], Salida deseada: 0.0\n",
            "Salida calculada: 0.3125661015510559\n",
            "Pérdida actual: 0.09769757091999054\n",
            "\n",
            "Entrada: [0. 0.], Salida deseada: 0.0\n",
            "Salida calculada: 0.7687920928001404\n",
            "Pérdida actual: 0.5910412669181824\n",
            "Pérdida promedio en la época 10: 0.2785058133304119\n",
            "Pesos actualizados: [-0.9811536 -1.0487957]\n",
            "Umbral actualizado (theta): -1.1741726398468018\n"
          ]
        }
      ],
      "source": [
        "#Pytorch Explicado epoca por epoca\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Datos de entrenamiento\n",
        "X = torch.tensor([[1, 0], [0, 1], [1, 1], [0, 0]], dtype=torch.float32)  # Entradas\n",
        "D = torch.tensor([[1], [1], [0], [0]], dtype=torch.float32)  # Salidas deseadas\n",
        "\n",
        "# Inicializar los pesos W y el umbral theta\n",
        "n_inputs = X.shape[1]\n",
        "weights = torch.randn((n_inputs, 1), requires_grad=True)  # Pesos aleatorios\n",
        "theta = torch.randn((1,), requires_grad=True)  # Umbral aleatorio\n",
        "learning_rate = 0.1  # Coeficiente de aprendizaje\n",
        "\n",
        "# Optimizador\n",
        "optimizer = optim.SGD([weights, theta], lr=learning_rate)\n",
        "\n",
        "# Función de activación (sigmoide)\n",
        "def activation(y):\n",
        "    return torch.sigmoid(y)\n",
        "\n",
        "# Función de pérdida (error cuadrático medio)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Mostrar los valores iniciales\n",
        "print(f\"Pesos iniciales: {weights.detach().numpy().flatten()}\")\n",
        "print(f\"Umbral inicial (theta): {theta.item()}\")\n",
        "\n",
        "# Entrenamiento\n",
        "for epoch in range(10):  # Número de iteraciones\n",
        "    total_loss = 0  # Acumular la pérdida\n",
        "    print(f\"\\n--- Época {epoch + 1} ---\")\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        # Datos de entrenamiento actuales\n",
        "        x = X[i:i+1]  # Par de entrenamiento\n",
        "        d = D[i:i+1]  # Salida deseada\n",
        "\n",
        "        print(f\"\\nEntrada: {x.numpy().flatten()}, Salida deseada: {d.item()}\")\n",
        "\n",
        "        # Paso 1: Propagación hacia adelante\n",
        "        y = activation(torch.matmul(x, weights) - theta)  # Salida calculada\n",
        "        print(f\"Salida calculada: {y.item()}\")\n",
        "\n",
        "        # Paso 2: Calcular la pérdida\n",
        "        loss = criterion(y, d)  # Pérdida\n",
        "        print(f\"Pérdida actual: {loss.item()}\")\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Paso 3: Retropropagación\n",
        "        optimizer.zero_grad()  # Reiniciar gradientes\n",
        "        loss.backward()  # Calcular gradientes\n",
        "        optimizer.step()  # Actualizar los parámetros\n",
        "\n",
        "    # Mostrar la pérdida promedio por época\n",
        "    print(f\"Pérdida promedio en la época {epoch + 1}: {total_loss / len(X)}\")\n",
        "    print(f\"Pesos actualizados: {weights.detach().numpy().flatten()}\")\n",
        "    print(f\"Umbral actualizado (theta): {theta.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch hasta la iteracion 100\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# Datos de entrenamiento\n",
        "X = torch.tensor([[1, 0], [0, 1], [1, 1], [0, 0]], dtype=torch.float32)  # Entradas\n",
        "D = torch.tensor([[1], [1], [0], [0]], dtype=torch.float32)  # Salidas deseadas\n",
        "# Inicializar los pesos W y el umbral theta\n",
        "n_inputs = X.shape[1]\n",
        "weights = torch.randn((n_inputs, 1), requires_grad=True)  # Pesos aleatorios\n",
        "theta = torch.randn((1,), requires_grad=True)  # Umbral aleatorio\n",
        "learning_rate = 0.1  # Coeficiente de aprendizaje\n",
        "# Optimizador\n",
        "optimizer = optim.SGD([weights, theta], lr=learning_rate)\n",
        "# Función de activación (sigmoide)\n",
        "def activation(y):\n",
        "    return torch.sigmoid(y)\n",
        "# Función de pérdida (error cuadrático medio)\n",
        "criterion = nn.MSELoss()\n",
        "# Entrenamiento\n",
        "for epoch in range(100):  # Número de iteraciones\n",
        "    total_loss = 0  # Acumular la pérdida\n",
        "    for i in range(len(X)):\n",
        "        # Paso 1: Propagación hacia adelante\n",
        "        x = X[i:i+1]  # Par de entrenamiento\n",
        "        d = D[i:i+1]  # Salida deseada\n",
        "        y = activation(torch.matmul(x, weights) - theta)  # Salida calculada\n",
        "\n",
        "        # Paso 2: Calcular la pérdida\n",
        "        loss = criterion(y, d)  # Pérdida\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Paso 3: Retropropagación\n",
        "        optimizer.zero_grad()  # Reiniciar gradientes\n",
        "        loss.backward()  # Calcular gradientes\n",
        "        optimizer.step()  # Actualizar los parámetros\n",
        "\n",
        "    # Mostrar la pérdida promedio por época\n",
        "    print(f\"Época {epoch + 1}, Pérdida: {total_loss / len(X)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jqu2kow0Lan",
        "outputId": "6e458e55-e25b-40e4-8425-d9c11efed2ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1, Pérdida: 0.2871041912585497\n",
            "Época 2, Pérdida: 0.2859796527773142\n",
            "Época 3, Pérdida: 0.2849505692720413\n",
            "Época 4, Pérdida: 0.28400709480047226\n",
            "Época 5, Pérdida: 0.2831403370946646\n",
            "Época 6, Pérdida: 0.2823421359062195\n",
            "Época 7, Pérdida: 0.2816051207482815\n",
            "Época 8, Pérdida: 0.280922744423151\n",
            "Época 9, Pérdida: 0.2802890036255121\n",
            "Época 10, Pérdida: 0.27969865687191486\n",
            "Época 11, Pérdida: 0.27914697118103504\n",
            "Época 12, Pérdida: 0.2786297984421253\n",
            "Época 13, Pérdida: 0.27814333513379097\n",
            "Época 14, Pérdida: 0.27768433652818203\n",
            "Época 15, Pérdida: 0.2772498708218336\n",
            "Época 16, Pérdida: 0.2768373526632786\n",
            "Época 17, Pérdida: 0.2764444462954998\n",
            "Época 18, Pérdida: 0.2760691810399294\n",
            "Época 19, Pérdida: 0.27570975199341774\n",
            "Época 20, Pérdida: 0.27536453679203987\n",
            "Época 21, Pérdida: 0.27503221295773983\n",
            "Época 22, Pérdida: 0.27471146546304226\n",
            "Época 23, Pérdida: 0.2744012326002121\n",
            "Época 24, Pérdida: 0.27410057932138443\n",
            "Época 25, Pérdida: 0.27380860410630703\n",
            "Época 26, Pérdida: 0.27352461218833923\n",
            "Época 27, Pérdida: 0.2732478678226471\n",
            "Época 28, Pérdida: 0.2729778476059437\n",
            "Época 29, Pérdida: 0.2727139573544264\n",
            "Época 30, Pérdida: 0.27245576679706573\n",
            "Época 31, Pérdida: 0.27220289409160614\n",
            "Época 32, Pérdida: 0.2719549760222435\n",
            "Época 33, Pérdida: 0.27171171084046364\n",
            "Época 34, Pérdida: 0.2714727409183979\n",
            "Época 35, Pérdida: 0.27123789861798286\n",
            "Época 36, Pérdida: 0.27100690081715584\n",
            "Época 37, Pérdida: 0.2707795910537243\n",
            "Época 38, Pérdida: 0.2705557979643345\n",
            "Época 39, Pérdida: 0.2703353129327297\n",
            "Época 40, Pérdida: 0.2701180949807167\n",
            "Época 41, Pérdida: 0.2699039466679096\n",
            "Época 42, Pérdida: 0.2696928232908249\n",
            "Época 43, Pérdida: 0.2694845460355282\n",
            "Época 44, Pérdida: 0.2692791074514389\n",
            "Época 45, Pérdida: 0.2690764367580414\n",
            "Época 46, Pérdida: 0.2688763961195946\n",
            "Época 47, Pérdida: 0.2686789855360985\n",
            "Época 48, Pérdida: 0.26848412677645683\n",
            "Época 49, Pérdida: 0.26829176023602486\n",
            "Época 50, Pérdida: 0.26810192689299583\n",
            "Época 51, Pérdida: 0.2679144889116287\n",
            "Época 52, Pérdida: 0.2677294462919235\n",
            "Época 53, Pérdida: 0.26754679530858994\n",
            "Época 54, Pérdida: 0.267366461455822\n",
            "Época 55, Pérdida: 0.26718848943710327\n",
            "Época 56, Pérdida: 0.2670127786695957\n",
            "Época 57, Pérdida: 0.26683932170271873\n",
            "Época 58, Pérdida: 0.2666681744158268\n",
            "Época 59, Pérdida: 0.26649924367666245\n",
            "Época 60, Pérdida: 0.2663324810564518\n",
            "Época 61, Pérdida: 0.2661679573357105\n",
            "Época 62, Pérdida: 0.26600561663508415\n",
            "Época 63, Pérdida: 0.2658454440534115\n",
            "Época 64, Pérdida: 0.26568740978837013\n",
            "Época 65, Pérdida: 0.2655315287411213\n",
            "Época 66, Pérdida: 0.2653777599334717\n",
            "Época 67, Pérdida: 0.2652260921895504\n",
            "Época 68, Pérdida: 0.26507653295993805\n",
            "Época 69, Pérdida: 0.26492904126644135\n",
            "Época 70, Pérdida: 0.2647836022078991\n",
            "Época 71, Pérdida: 0.2646402567625046\n",
            "Época 72, Pérdida: 0.26449892297387123\n",
            "Época 73, Pérdida: 0.26435961574316025\n",
            "Época 74, Pérdida: 0.26422230154275894\n",
            "Época 75, Pérdida: 0.2640870064496994\n",
            "Época 76, Pérdida: 0.26395367830991745\n",
            "Época 77, Pérdida: 0.2638223059475422\n",
            "Época 78, Pérdida: 0.26369285956025124\n",
            "Época 79, Pérdida: 0.2635653652250767\n",
            "Época 80, Pérdida: 0.2634397819638252\n",
            "Época 81, Pérdida: 0.2633161023259163\n",
            "Época 82, Pérdida: 0.26319434121251106\n",
            "Época 83, Pérdida: 0.2630743980407715\n",
            "Época 84, Pérdida: 0.26295631378889084\n",
            "Época 85, Pérdida: 0.26284002885222435\n",
            "Época 86, Pérdida: 0.2627255879342556\n",
            "Época 87, Pérdida: 0.2626129500567913\n",
            "Época 88, Pérdida: 0.2625020854175091\n",
            "Época 89, Pérdida: 0.262392982840538\n",
            "Época 90, Pérdida: 0.26228558272123337\n",
            "Época 91, Pérdida: 0.2621799223124981\n",
            "Época 92, Pérdida: 0.2620759755373001\n",
            "Época 93, Pérdida: 0.26197370141744614\n",
            "Época 94, Pérdida: 0.2618730962276459\n",
            "Época 95, Pérdida: 0.26177413016557693\n",
            "Época 96, Pérdida: 0.2616768032312393\n",
            "Época 97, Pérdida: 0.26158110797405243\n",
            "Época 98, Pérdida: 0.2614869549870491\n",
            "Época 99, Pérdida: 0.2613944038748741\n",
            "Época 100, Pérdida: 0.2613034062087536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TENSORFLOW:\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Datos de entrenamiento\n",
        "X = np.array([[1, 0], [0, 1], [1, 1], [0, 0]])  # Entradas (X1, X2)\n",
        "D = np.array([[1], [1], [0], [0]])  # Salidas deseadas\n",
        "\n",
        "# Inicializar los pesos W y el umbral theta\n",
        "n_inputs = X.shape[1]\n",
        "weights = tf.Variable(tf.random.uniform((n_inputs, 1), -1, 1))  # Pesos aleatorios\n",
        "theta = tf.Variable(tf.random.uniform((1,), -1, 1))  # Umbral\n",
        "learning_rate = 0.1  # Coeficiente de aprendizaje\n",
        "\n",
        "# Función de activación (por ejemplo, escalón)\n",
        "def activation(y):\n",
        "    return tf.where(y >= 0, 1.0, 0.0)\n",
        "\n",
        "# Entrenamiento\n",
        "for epoch in range(100):  # Número de iteraciones\n",
        "    for i in range(len(X)):\n",
        "        # Paso 1: Propagación hacia adelante\n",
        "        x = tf.constant(X[i:i+1], dtype=tf.float32)  # Par de entrenamiento\n",
        "        d = tf.constant(D[i:i+1], dtype=tf.float32)  # Salida deseada\n",
        "        y = activation(tf.matmul(x, weights) - theta)  # Salida calculada\n",
        "\n",
        "        # Paso 2: Calcular el error\n",
        "        error = d - y\n",
        "\n",
        "        # Paso 3: Retropropagación (ajustar pesos y umbral)\n",
        "        weights.assign_add(learning_rate * tf.matmul(tf.transpose(x), error))\n",
        "        theta.assign_sub(learning_rate * tf.reduce_sum(error)[..., tf.newaxis])  # Ajustar el umbral\n",
        "\n",
        "# Mostrar los pesos y el umbral ajustados\n",
        "print(\"Pesos ajustados:\", weights.numpy())\n",
        "print(\"Umbral ajustado:\", theta.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32gzFvuW6XEN",
        "outputId": "5001b4bb-6da1-4662-a60b-9bb61c31e117"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos ajustados: [[-0.16090977]\n",
            " [-0.21128793]]\n",
            "Umbral ajustado: [-0.02814751]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KERAS:\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Datos de entrenamiento\n",
        "X = np.array([[1, 0], [0, 1], [1, 1], [0, 0]])  # Entradas\n",
        "D = np.array([[1], [1], [0], [0]])  # Salidas deseadas\n",
        "\n",
        "# Crear un modelo secuencial en Keras\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,  # Nodo único (salida)\n",
        "        input_shape=(2,),  # Dimensión de las entradas\n",
        "        activation=\"sigmoid\",  # Aproximar la función escalón con sigmoide\n",
        "        use_bias=True  # Incluir el umbral (bias)\n",
        "    )\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),  # Optimización con SGD\n",
        "    loss='binary_crossentropy',  # Pérdida para problemas binarios\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X, D, epochs=100, verbose=0)  # 100 iteraciones de entrenamiento\n",
        "\n",
        "# Mostrar los pesos y el umbral ajustados\n",
        "weights, bias = model.layers[0].get_weights()\n",
        "print(\"Pesos ajustados:\", weights.flatten())\n",
        "print(\"Umbral ajustado:\", bias.flatten())\n",
        "\n",
        "# Probar el modelo con la función escalón\n",
        "predictions = model.predict(X)\n",
        "step_predictions = np.where(predictions >= 0.5, 1, 0)  # Aplicar función escalón\n",
        "print(\"Predicciones (escalón):\", step_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE8CJ7m6f5U",
        "outputId": "e3350939-0413-4bbc-b9a1-cad4ce6c3908"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos ajustados: [-0.60051495 -0.27795208]\n",
            "Umbral ajustado: [0.49392933]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Predicciones (escalón): [[0]\n",
            " [1]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBcZuF246OIV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}